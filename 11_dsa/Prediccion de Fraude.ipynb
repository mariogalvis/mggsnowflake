{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "mwvazcydpzdaus3fvlwq",
   "authorId": "9067214587578",
   "authorName": "MGALVIS",
   "authorEmail": "mario.galvis@snowflake.com",
   "sessionId": "3e8b5a26-5afa-4804-ae8d-23113a01c1ce",
   "lastEditTime": 1759774907725
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "id": "4663efbc-b378-422a-8cb1-c8c9f713823c",
   "metadata": {
    "language": "python",
    "name": "cell1"
   },
   "outputs": [],
   "source": "# Generated by Snowflake Copilot\nimport streamlit as st\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\nfrom snowflake.snowpark.context import get_active_session\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Configuraci√≥n de la p√°gina de Streamlit\n#st.set_page_config(page_title=\"Detector de Fraude Interactivo\", page_icon=\"üîç\", layout=\"wide\")\n\n@st.cache_data\ndef load_and_prepare_data():\n    \"\"\"\n    Funci√≥n para cargar y preparar los datos desde Snowflake.\n    - Conecta a la sesi√≥n activa de Snowflake\n    - Carga la tabla de transacciones\n    - Separa caracter√≠sticas (X) de la variable objetivo (y)\n    - Codifica variables categ√≥ricas usando LabelEncoder\n    \"\"\"\n    # Establecer conexi√≥n con Snowflake\n    session = get_active_session()\n    table_name = \"DETECCION_FRAUDE.FRAUD_DETECTION_SCHEMA.TRANSACCIONES_AVANZADAS\"\n    \n    # Cargar datos completos desde Snowflake a pandas\n    df = session.table(table_name).to_pandas()\n    \n    # Identificar columnas de caracter√≠sticas (excluir ID, target y timestamps)\n    feature_columns = [col for col in df.columns if col not in ['TRANSACTION_ID', 'IS_FRAUD', 'CREATED_AT', 'UPDATED_AT']]\n    X = df[feature_columns].copy()\n    y = df['IS_FRAUD'].copy()\n    \n    # Codificar variables categ√≥ricas a num√©ricas\n    categorical_columns = X.select_dtypes(include=['object']).columns.tolist()\n    label_encoders = {}\n    for col in categorical_columns:\n        le = LabelEncoder()\n        X[col] = le.fit_transform(X[col].astype(str))\n        label_encoders[col] = le\n    \n    return X, y, label_encoders, feature_columns\n\n@st.cache_resource\ndef train_model(X, y):\n    \"\"\"\n    Funci√≥n para entrenar el modelo de detecci√≥n de fraude.\n    - Divide los datos en entrenamiento y prueba (80/20)\n    - Entrena un Random Forest Classifier\n    - Retorna el modelo entrenado y datos de entrenamiento\n    \"\"\"\n    # Dividir datos manteniendo la proporci√≥n de fraude en ambos conjuntos\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n    \n    # Entrenar modelo Random Forest con 100 √°rboles\n    model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n    model.fit(X_train, y_train)\n    \n    return model, X_train, X_test, y_train, y_test\n\ndef calculate_model_metrics(model, X_test, y_test):\n    \"\"\"\n    Funci√≥n para calcular m√©tricas de rendimiento del modelo.\n    - Calcula predicciones y probabilidades\n    - Computa m√©tricas: accuracy, precision, recall, F1, ROC AUC\n    \"\"\"\n    # Generar predicciones binarias y probabilidades\n    y_pred = model.predict(X_test)\n    y_pred_proba = model.predict_proba(X_test)[:, 1]\n    \n    # Calcular m√©tricas de rendimiento\n    accuracy = accuracy_score(y_test, y_pred)\n    precision = precision_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    roc_auc = roc_auc_score(y_test, y_pred_proba)\n    \n    return accuracy, precision, recall, f1, roc_auc\n\n# T√≠tulo principal de la aplicaci√≥n\nst.title(\"üîç Detector de Fraude Interactivo\")\nst.markdown(\"### Ajusta las variables y predice la probabilidad de fraude\")\n\ntry:\n    # ETAPA 1: CARGA Y PREPARACI√ìN DE DATOS\n    st.info(\"üîÑ Cargando y preparando datos desde Snowflake...\")\n    X, y, label_encoders, feature_columns = load_and_prepare_data()\n    \n    # ETAPA 2: ENTRENAMIENTO DEL MODELO\n    st.info(\"ü§ñ Entrenando modelo de Machine Learning...\")\n    model, X_train, X_test, y_train, y_test = train_model(X, y)\n    \n    # ETAPA 3: EVALUACI√ìN DEL MODELO\n    accuracy, precision, recall, f1, roc_auc = calculate_model_metrics(model, X_test, y_test)\n    \n    st.success(f\"‚úÖ Modelo entrenado exitosamente con {len(feature_columns)} caracter√≠sticas\")\n    \n    # ETAPA 4: INTERFAZ DE USUARIO PARA ENTRADA DE DATOS\n    # Crear dos columnas para organizar los controles de entrada\n    col1, col2 = st.columns(2)\n    \n    with col1:\n        # Secci√≥n de variables de transacci√≥n\n        st.subheader(\"üí∞ Variables de Transacci√≥n\")\n        monto_transaccion = st.slider(\"Monto de Transacci√≥n ($)\", 0, 50000, 1000, 100)\n        distancia_domicilio = st.slider(\"Distancia del Domicilio (km)\", 0, 10000, 100, 50)\n        diferencia_residencia = st.slider(\"Diferencia Residencia-Compra (km)\", 0, 10000, 50, 50)\n        variacion_gasto = st.slider(\"Variaci√≥n Gasto Mes Anterior ($)\", -5000, 5000, 0, 100)\n        hora_dia = st.slider(\"Hora del D√≠a\", 0, 23, 12, 1)\n        \n        # Secci√≥n de variables geogr√°ficas\n        st.subheader(\"üåç Variables Geogr√°ficas\")\n        pais_origen = st.selectbox(\"Pa√≠s Origen\", [\"USA\", \"MEX\", \"CAN\", \"ESP\", \"FRA\", \"GBR\"])\n        pais_destino = st.selectbox(\"Pa√≠s Destino\", [\"USA\", \"MEX\", \"CAN\", \"ESP\", \"FRA\", \"GBR\", \"RUS\", \"CHN\"])\n        diferencia_horaria = st.slider(\"Diferencia Horaria (horas)\", 0, 24, 0, 1)\n        \n    with col2:\n        # Secci√≥n de variables de seguridad\n        st.subheader(\"üîí Variables de Seguridad\")\n        usa_vpn = st.checkbox(\"Usa VPN/Proxy\")\n        usa_autocompletado = st.checkbox(\"Usa Autocompletado/Copy-Paste\")\n        usa_emails_temporales = st.checkbox(\"Usa Emails Temporales\")\n        dispositivo_confiable = st.checkbox(\"Dispositivo Confiable\")\n        cambio_geolocalizacion_imposible = st.checkbox(\"Cambio Geolocalizaci√≥n Imposible\")\n        \n        # Secci√≥n de variables de comportamiento\n        st.subheader(\"üë§ Variables de Comportamiento\")\n        antiguedad_cuenta = st.slider(\"Antig√ºedad Cuenta (d√≠as)\", 1, 3650, 365, 30)\n        intentos_login_24h = st.slider(\"Intentos Login 24h\", 1, 20, 3, 1)\n        velocidad_digitacion = st.slider(\"Velocidad Digitaci√≥n (CPM)\", 10, 200, 60, 5)\n        transacciones_internacionales = st.slider(\"Transacciones Internacionales\", 0, 10, 0, 1)\n        \n        # Secci√≥n de variables financieras\n        st.subheader(\"üí≥ Variables Financieras\")\n        porcentaje_uso_limite = st.slider(\"% Uso L√≠mite Cr√©dito\", 0, 100, 30, 5)\n        historial_contracargos = st.slider(\"Historial Contracargos\", 0, 10, 0, 1)\n    \n    st.markdown(\"---\")\n    \n    # ETAPA 5: BOT√ìN DE PREDICCI√ìN Y PROCESAMIENTO\n    if st.button(\"üéØ **PREDECIR FRAUDE**\", type=\"primary\", use_container_width=True):\n        \n        # Crear diccionario con los valores ingresados por el usuario\n        user_input = {\n            'MONTO_TRANSACCION': float(monto_transaccion),\n            'DISTANCIA_DOMICILIO_KM': float(distancia_domicilio),\n            'DIFERENCIA_RESIDENCIA_COMPRA_KM': float(diferencia_residencia),\n            'VARIACION_GASTO_MES_ANTERIOR': float(variacion_gasto),\n            'HORA_DIA': int(hora_dia),\n            'PAIS_ORIGEN': pais_origen,\n            'PAIS_DESTINO': pais_destino,\n            'DIFERENCIA_HORARIA_HORAS': int(diferencia_horaria),\n            'USA_VPN_PROXY': usa_vpn,\n            'USO_AUTOCOMPLETADO_COPYPASTE': usa_autocompletado,\n            'USA_EMAILS_TEMPORALES': usa_emails_temporales,\n            'DISPOSITIVO_CONFIABLE': dispositivo_confiable,\n            'CAMBIO_GEOLOCALIZACION_IMPOSIBLE': cambio_geolocalizacion_imposible,\n            'ANTIGUEDAD_CUENTA_DIAS': int(antiguedad_cuenta),\n            'INTENTOS_LOGIN_24H': int(intentos_login_24h),\n            'VELOCIDAD_DIGITACION_CPM': float(velocidad_digitacion),\n            'TRANSACCIONES_INTERNACIONALES': int(transacciones_internacionales),\n            'PORCENTAJE_USO_LIMITE': float(porcentaje_uso_limite),\n            'HISTORIAL_CONTRACARGOS': int(historial_contracargos)\n        }\n        \n        # Convertir a DataFrame para procesamiento\n        input_df = pd.DataFrame([user_input])\n        \n        # ETAPA 6: COMPLETAR CARACTER√çSTICAS FALTANTES\n        # Rellenar caracter√≠sticas no especificadas por el usuario con valores por defecto\n        for col in feature_columns:\n            if col not in input_df.columns:\n                if col in X.columns:\n                    # Usar la mediana de los datos de entrenamiento como valor por defecto\n                    input_df[col] = X[col].median()\n                else:\n                    input_df[col] = 0\n        \n        # ETAPA 7: CODIFICACI√ìN DE VARIABLES CATEG√ìRICAS\n        # Aplicar la misma codificaci√≥n usada durante el entrenamiento\n        categorical_columns = ['PAIS_ORIGEN', 'PAIS_DESTINO']\n        for col in categorical_columns:\n            if col in input_df.columns and col in label_encoders:\n                try:\n                    input_df[col] = label_encoders[col].transform(input_df[col].astype(str))\n                except ValueError:\n                    # Si el valor no fue visto durante el entrenamiento, usar 0\n                    input_df[col] = 0\n        \n        # Asegurar que las columnas est√©n en el mismo orden que durante el entrenamiento\n        input_df = input_df[feature_columns]\n        \n        # ETAPA 8: INFERENCIA DEL MODELO\n        # Generar probabilidad de fraude y predicci√≥n binaria\n        fraud_probability = model.predict_proba(input_df)[0, 1]\n        fraud_prediction = model.predict(input_df)[0]\n        \n        # ETAPA 9: MOSTRAR RESULTADOS DE LA PREDICCI√ìN\n        st.markdown(\"---\")\n        st.subheader(\"üìä Resultados de la Predicci√≥n\")\n        \n        # Mostrar m√©tricas principales en columnas\n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            st.metric(\"Probabilidad de Fraude\", f\"{fraud_probability:.1%}\")\n        \n        with col2:\n            prediction_text = \"üö® FRAUDE\" if fraud_prediction else \"‚úÖ LEG√çTIMA\"\n            st.metric(\"Predicci√≥n\", prediction_text)\n        \n        with col3:\n            # Determinar nivel de riesgo basado en probabilidad\n            if fraud_probability > 0.7:\n                risk_level = \"üî¥ ALTO RIESGO\"\n            elif fraud_probability > 0.4:\n                risk_level = \"üü° RIESGO MEDIO\"\n            else:\n                risk_level = \"üü¢ BAJO RIESGO\"\n            st.metric(\"Nivel de Riesgo\", risk_level)\n        \n        # Barra de progreso visual para la probabilidad\n        progress_bar = st.progress(fraud_probability)\n        \n        # ETAPA 10: ALERTAS Y RECOMENDACIONES\n        # Mostrar alertas basadas en el nivel de riesgo\n        if fraud_probability > 0.6:\n            st.error(f\"‚ö†Ô∏è **ALERTA DE FRAUDE**: Probabilidad alta ({fraud_probability:.1%})\")\n            st.markdown(\"**Recomendaci√≥n**: Revisar manualmente la transacci√≥n\")\n        elif fraud_probability > 0.3:\n            st.warning(f\"‚ö†Ô∏è **PRECAUCI√ìN**: Probabilidad media ({fraud_probability:.1%})\")\n            st.markdown(\"**Recomendaci√≥n**: Verificaci√≥n adicional requerida\")\n        else:\n            st.success(f\"‚úÖ **TRANSACCI√ìN SEGURA**: Probabilidad baja ({fraud_probability:.1%})\")\n            st.markdown(\"**Recomendaci√≥n**: Proceder con la transacci√≥n\")\n        \n        # ETAPA 11: AN√ÅLISIS DE FACTORES DE RIESGO\n        # Identificar autom√°ticamente factores de riesgo presentes\n        risk_factors = []\n        if usa_vpn:\n            risk_factors.append(\"Uso de VPN/Proxy\")\n        if usa_autocompletado:\n            risk_factors.append(\"Uso de autocompletado\")\n        if usa_emails_temporales:\n            risk_factors.append(\"Emails temporales\")\n        if monto_transaccion > 5000:\n            risk_factors.append(f\"Monto alto (${monto_transaccion:,})\")\n        if distancia_domicilio > 1000:\n            risk_factors.append(f\"Distancia alta ({distancia_domicilio} km)\")\n        if cambio_geolocalizacion_imposible:\n            risk_factors.append(\"Cambio geolocalizaci√≥n imposible\")\n        \n        # Mostrar factores de riesgo si existen\n        if risk_factors:\n            st.subheader(\"‚ö†Ô∏è Factores de Riesgo Identificados\")\n            for factor in risk_factors:\n                st.write(f\"‚Ä¢ {factor}\")\n\n    # ETAPA 12: MOSTRAR M√âTRICAS DE RENDIMIENTO DEL MODELO\n    st.markdown(\"---\")\n    st.subheader(\"üìà Rendimiento del Modelo de Machine Learning\")\n    \n    # Crear columnas para mostrar las m√©tricas\n    col1, col2, col3, col4, col5 = st.columns(5)\n    \n    with col1:\n        st.metric(\"Accuracy\", f\"{accuracy:.2%}\")\n    with col2:\n        st.metric(\"Precision\", f\"{precision:.2%}\")\n    with col3:\n        st.metric(\"Recall\", f\"{recall:.2%}\")\n    with col4:\n        st.metric(\"F1-Score\", f\"{f1:.2%}\")\n    with col5:\n        st.metric(\"ROC AUC\", f\"{roc_auc:.2%}\")\n    \n    # Informaci√≥n adicional del modelo\n    st.info(f\"\"\"\n    **Informaci√≥n del Modelo:**\n    - **Algoritmo**: Random Forest Classifier (100 √°rboles)\n    - **Caracter√≠sticas**: {len(feature_columns)} variables\n    - **Datos de entrenamiento**: {len(X_train):,} transacciones\n    - **Datos de prueba**: {len(X_test):,} transacciones\n    - **Tasa de fraude**: {y.mean():.2%}\n    \"\"\")\n    \n    # Mostrar interpretaci√≥n de las m√©tricas\n    st.markdown(\"\"\"\n    **Interpretaci√≥n de M√©tricas:**\n    - **Accuracy**: Porcentaje de predicciones correctas\n    - **Precision**: De las transacciones predichas como fraude, qu√© porcentaje realmente lo son\n    - **Recall**: De todas las transacciones fraudulentas, qu√© porcentaje detectamos\n    - **F1-Score**: Media arm√≥nica entre precision y recall\n    - **ROC AUC**: Capacidad del modelo para distinguir entre fraude y no fraude\n    \"\"\")\n\nexcept Exception as e:\n    # Manejo de errores con mensaje informativo\n    st.error(f\"Error al cargar el modelo: {str(e)}\")\n    st.info(\"Aseg√∫rate de que la tabla de datos est√© disponible en Snowflake\")\n\n# Pie de p√°gina con informaci√≥n del desarrollador\nst.markdown(\"---\")\nst.markdown(\"**Desarrollado con Snowflake ML** | Modelo: Random Forest | **Comentarios agregados para comprensi√≥n completa**\")",
   "execution_count": null
  }
 ]
}