{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0549990d-647e-420f-a9d1-bb7cfdbc9b45",
   "metadata": {
    "collapsed": false,
    "name": "selectpackages"
   },
   "source": [
    "# Credit Card Fraud Detection: Harnessing the Power of Machine Learning in Snowflake ML\n",
    "\n",
    "The prerequisite for this notebook is the completion of setup in the 1_cc_fins_setup notebook.\n",
    "\n",
    "To get started, click the **Start** button! Once it says **Active**, you're ready to run the rest of the Notebook. All the packages have been pre-uploaded. \n",
    "We will be consuming the features from the Feature Store.\n",
    "\n",
    "### Snowflake ML Feature Store\n",
    "A Python SDK for defining, registering, retrieving, and managing features.\n",
    "\n",
    "Entity: Entities are the underlying objects that features and feature views are associated with. They encapsulate the join keys used for feature lookups. \n",
    "\n",
    "FeatureView: A feature view is a group of logically-related features that are refreshed on the same schedule.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "import_libs"
   },
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "\n",
    "# Third-party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# Snowflake library imports\n",
    "import streamlit as st\n",
    "\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from snowflake.ml.feature_store import (\n",
    "FeatureStore,\n",
    "FeatureView,\n",
    "CreationMode)\n",
    "\n",
    "from snowflake.ml import dataset\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark import types as T\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()\n",
    "session.query_tag = {\"origin\":\"sf_sit-is\", \n",
    "                     \"name\":\"credit_card_fraud\", \n",
    "                     \"version\":{\"major\":1, \"minor\":0},\n",
    "                     \"attributes\":{\"is_quickstart\":0, \"source\":\"notebook\"}}\n",
    "\n",
    "# Set the style for the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Custom color palettes\n",
    "colors = {\n",
    "    'Non-Fraud Bars': '#4C72B0',\n",
    "    'Fraud Bars': '#55A868',\n",
    "    'Non-Fraud Line': '#1f77b4',\n",
    "    'Fraud Line': '#ff7f0e'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416af38-ac2f-4ad7-8be4-5b102d8c9381",
   "metadata": {
    "collapsed": false,
    "name": "use_objects"
   },
   "source": [
    "Set the context for the database and warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d50cbf4-0c8d-4950-86cb-114990437ac9",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "set_context"
   },
   "outputs": [],
   "source": [
    "\n",
    "session.sql(\"USE ROLE SYSADMIN\").collect()\n",
    "session.sql(\"USE DATABASE CC_FINS_DB\").collect()\n",
    "session.sql(\"USE SCHEMA ANALYTICS\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c40a69-72b9-4ff8-993f-87a302db80d0",
   "metadata": {
    "collapsed": false,
    "name": "Spine_DF"
   },
   "source": [
    "Generating Datasets for Training\n",
    "We are now ready to generate our training set. We'll define a spine DataFrame to form the backbone of our generated dataset and pass it into FeatureStore.generate_dataset() along with our Feature Views.\n",
    "\n",
    "NOTE: The spine serves as a request template and specifies the entities, labels and timestamps (when applicable). The feature store then attaches feature values along the spine using an AS-OF join to efficiently combine and serve the relevant, point-in-time correct feature data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d975a-68a4-431d-b148-5669bb69a209",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_spine_df"
   },
   "outputs": [],
   "source": [
    "session.sql(\"create or replace TABLE TRANSACTIONS_DATA (USER_ID VARCHAR,TRANSACTION_ID VARCHAR(16777216),IS_FRAUD VARCHAR)\").collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0945da1-ab8f-460e-8d3c-37fb84643adb",
   "metadata": {
    "collapsed": false,
    "name": "save_spinetransactions"
   },
   "source": [
    "Save the spine dataframe to a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae32a534-2538-4499-bb79-6d24dc824bfc",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "TRANSACTIONS_DATA"
   },
   "outputs": [],
   "source": [
    "session.sql(\"insert into TRANSACTIONS_DATA(User_ID, Transaction_ID, IS_FRAUD) SELECT distinct User_ID, Transaction_ID, IS_FRAUD FROM CREDITCARD_TRANSACTIONS\").collect()\n",
    "TRANSACTIONS_DATA_df = session.table(\"TRANSACTIONS_DATA\")\n",
    "TRANSACTIONS_DATA_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44746866-794b-4677-ac1a-7cf7b3ab7b24",
   "metadata": {
    "collapsed": false,
    "name": "stats_using_describe"
   },
   "source": [
    "Descriptive statistics include those that summarize the central tendency, dispersion and shape of a dataset’s distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d672cfd-b87b-48c0-a396-ebc9466bd33a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "stats"
   },
   "outputs": [],
   "source": [
    "full_df = session.sql(\"SELECT * FROM CREDITCARD_TRANSACTIONS\")\n",
    "full_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc7dbca-1884-4c9a-bb17-2eaee4e6d616",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "list_columns"
   },
   "outputs": [],
   "source": [
    "full_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e781bc19-9f46-4718-92a0-d6ae5ba356c7",
   "metadata": {
    "collapsed": false,
    "name": "Chart_fraud_normal"
   },
   "source": [
    "Visualization of the fraud and normal data using a bar chart displayed in Streamlit. Shows the total number of distinct transactions for each fraud category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533372f2-1c62-453d-8b9a-2e19660ee2f9",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "visualization_stchart"
   },
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset=full_df.toPandas()\n",
    "# Group by 'IS_FRAUD' and count distinct TRANSACTION_ID\n",
    "df= TRANSACTIONS_DATA_df.select( F.col(\"TRANSACTION_ID\"),F.col(\"IS_FRAUD\")).groupBy(F.col(\"IS_FRAUD\")) \\\n",
    "          .agg(F.count_distinct(F.col(\"TRANSACTION_ID\")).alias(\"TOTAL_FRAUD\")) \n",
    "\n",
    "\n",
    "st.bar_chart(df,x=\"IS_FRAUD\",y=\"TOTAL_FRAUD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abf3398-c8ac-41fb-acba-07004c9f5e45",
   "metadata": {
    "collapsed": false,
    "name": "transaction_amounts"
   },
   "source": [
    "Create a histogram that shows the distribution of transaction amounts, distinguishing between fraudulent and non-fraudulent transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38ec496-bd4f-49ce-ad81-3a18e3089314",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "DistributionofTransactionAmounts"
   },
   "outputs": [],
   "source": [
    "\n",
    "dataset['IS_FRAUD'] = dataset['IS_FRAUD'].astype(int)\n",
    "# Set the style for the plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "# Background color\n",
    "background_color = \"#f0f0f0\"  # Light gray\n",
    "# 1. Distribution of Transaction Amounts\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.histplot(data=dataset, x='TRANSACTION_AMOUNT', hue='IS_FRAUD', kde=True, bins=50)\n",
    "plt.title('Distribution of Transaction Amounts')\n",
    "plt.xlabel('Transaction Amount')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title='Transaction', loc='upper right', labels=['Normal', 'Fraud'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc519ce7-c21a-460b-8a76-9dc0fe50c40d",
   "metadata": {
    "collapsed": false,
    "name": "distribution_clicks"
   },
   "source": [
    "Create a histogram that shows the distribution of clicks, distinguishing between fraudulent and non-fraudulent transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e4feee-00f6-4125-bbf0-31706ab2d6a3",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "Clicksandlogins_Distribution"
   },
   "outputs": [],
   "source": [
    "#CLICKS, LOGIN_PER_HOUR, and PAGES_VISITED Distributions\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Custom color palettes\n",
    "colors = {\n",
    "    'Normal Bars': '#4C72B0',\n",
    "    'Fraud Bars': '#55A868',\n",
    "    'Normal Line': '#1f77b4',\n",
    "    'Fraud Line': '#ff7f0e'\n",
    "}\n",
    "# 4. CLICKS Distribution\n",
    "plt.figure(figsize=(4, 4))\n",
    "sns.histplot(data=dataset, x='CLICKS', hue='IS_FRAUD', multiple='dodge', kde=True, bins=30)\n",
    "plt.title('Clicks Distribution')\n",
    "plt.xlabel('Clicks')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title='Transaction', loc='upper right', labels=['Normal', 'Fraud'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d7553-60ff-4f61-a0a9-bee290a4aa04",
   "metadata": {
    "collapsed": false,
    "name": "distribution_logins"
   },
   "source": [
    "Create a histogram that shows the distribution of logins, distinguishing between fraudulent and non-fraudulent transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8434ffc9-cbd7-40de-9936-bcff3284554b",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "LOGIN_PER_HOUR"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "sns.histplot(data=dataset, x='LOGIN_PER_HOUR', hue='IS_FRAUD', multiple='dodge', kde=True, bins=30)\n",
    "plt.title('Login Per Hour Distribution')\n",
    "plt.xlabel('Login Per Hour')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title='Is Fraud', loc='upper right', labels=['Non-Fraud', 'Fraud'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e8af8-6640-4f86-beee-3b73569e6b81",
   "metadata": {
    "collapsed": false,
    "name": "distribution_timeelapsed"
   },
   "source": [
    "Create a histogram that shows the distribution of time elapsed online, distinguishing between fraudulent and non-fraudulent transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dbda17-190e-408d-a56b-960ec83fa40c",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "TimeElapsedDistribution"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(4,4))\n",
    "sns.histplot(data=dataset, x='TIME_ELAPSED', hue='IS_FRAUD', kde=True, bins=50)\n",
    "plt.title('Time Elapsed Distribution')\n",
    "plt.xlabel('Time Elapsed (seconds)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(title='Is Fraud', loc='upper right', labels=['Non-Fraud', 'Fraud'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773a0b3a-28a7-4188-bb60-fadb18c594a1",
   "metadata": {
    "collapsed": false,
    "name": "distribution_location"
   },
   "source": [
    "Create a histogram that shows the distribution of location, distinguishing between fraudulent and non-fraudulent transactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6fcc1c-478e-4f6d-9af6-b906384ac933",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Geographical_Distribution"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define location coordinates\n",
    "location_coords = {\n",
    "    'New York': (40.7128, -74.0060),\n",
    "    'Los Angeles': (34.0522, -118.2437),\n",
    "    'Chicago': (41.8781, -87.6298),\n",
    "    'Houston': (29.7604, -95.3698),\n",
    "    'Phoenix': (33.4484, -112.0740),\n",
    "    'Philadelphia': (39.9526, -75.1652),\n",
    "    'San Antonio': (29.4241, -98.4936),\n",
    "    'San Diego': (32.7157, -117.1611),\n",
    "    'Dallas': (32.7767, -96.7970),\n",
    "    'San Jose': (37.3382, -121.8863),\n",
    "    'Moscow': (55.7558, 37.6176)  # Add Moscow coordinates\n",
    "}\n",
    "\n",
    "# Add latitude and longitude based on location\n",
    "dataset['LATITUDE'] = dataset['LOCATION'].map(lambda loc: location_coords.get(loc, (None, None))[0])\n",
    "dataset['LONGITUDE'] = dataset['LOCATION'].map(lambda loc: location_coords.get(loc, (None, None))[1])\n",
    "\n",
    "# Filter for plotting\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# Plot all locations\n",
    "scatter = plt.scatter(dataset['LONGITUDE'], dataset['LATITUDE'], \n",
    "                      c=dataset['IS_FRAUD'].map({0: 'purple', 1: 'red'}),\n",
    "                      alpha=0.5)\n",
    "\n",
    "# Create custom legend\n",
    "purple_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='purple', markersize=10, label='Normal')\n",
    "red_patch = plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='red', markersize=10, label='Fraud')\n",
    "\n",
    "# Plot details\n",
    "plt.title('Geographical Distribution of Transactions')\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "\n",
    "# Set legend with custom handles\n",
    "plt.legend(handles=[purple_patch, red_patch], title='Transaction Type', loc='upper left', bbox_to_anchor=(1, 1), frameon=True, fontsize='small')\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "# Set background color for the plot\n",
    "plt.gcf().set_facecolor(\"#f0f0f0\")  # Light gray\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820f773b-8220-47bf-a10e-0206a8bb1ef9",
   "metadata": {
    "collapsed": false,
    "name": "FS_Init"
   },
   "source": [
    "## Feature Store\n",
    "The feature store contains feature views for customers and transactions. Model features will be accessed from the feature store.\n",
    "\n",
    "**Snowflake Feature:** Feature Store (PrPr) - Easily find features that work with your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "Feature_Store"
   },
   "outputs": [],
   "source": [
    "# Access feature views\n",
    "\n",
    "fs = FeatureStore(\n",
    "    session=session,\n",
    "    database=\"CC_FINS_DB\",\n",
    "    name=\"ANALYTICS\",\n",
    "    default_warehouse=\"CC_FINS_WH\",\n",
    "    creation_mode=CreationMode.FAIL_IF_NOT_EXIST\n",
    ")\n",
    "\n",
    "customer_fv : FeatureView = fs.get_feature_view(\n",
    "    name='Customer_Features',\n",
    "    version='V1'\n",
    ")\n",
    "print(customer_fv)\n",
    "\n",
    "trans_fv : FeatureView = fs.get_feature_view(\n",
    "    name='Trans_Features',\n",
    "    version='V1'\n",
    ")\n",
    "print(trans_fv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514a2f99-3554-4c60-99bd-d7fd5cfd280d",
   "metadata": {
    "collapsed": false,
    "name": "create_dataset_split"
   },
   "source": [
    "Generate a training data set with the feature store’s generate_training_set method, which enriches a Snowpark DataFrame that contains the source data with the derived feature values. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56b86f-11bf-43a5-a8d5-994adfbdef3a",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_dataset"
   },
   "outputs": [],
   "source": [
    "# Get transactions dataset and get features from the feature store\n",
    "def create_dataset(spine_df, name):\n",
    "    train_dataset = fs.generate_dataset(\n",
    "    name=name,\n",
    "    spine_df=spine_df,\n",
    "    features=[customer_fv, trans_fv]\n",
    "    )\n",
    "    df = train_dataset.read.to_snowpark_dataframe()\n",
    "    return df\n",
    "# Split into train/validation/test\n",
    "\n",
    "\n",
    "datasets = TRANSACTIONS_DATA_df.random_split([.8,.2])\n",
    "\n",
    "# Build training tables\n",
    "train_df = create_dataset(datasets[0], \"train\")\n",
    "val_df = create_dataset(datasets[1], \"validation\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb91b85-2074-4516-b050-e48d24650097",
   "metadata": {
    "collapsed": false,
    "name": "training_dataset"
   },
   "source": [
    "View the training dataset.\n",
    "\n",
    "This contains the columns except for Ids. The Label is included here as this will be specified in the LABEL field during model training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849b67a7-74d3-454b-9505-54d0732ba22e",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "view_training_data"
   },
   "outputs": [],
   "source": [
    "train_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f57e9-512a-4988-b8c8-b4f68ec13c14",
   "metadata": {
    "collapsed": false,
    "name": "View_creation"
   },
   "source": [
    "Creating separate views for training and validation to be used with a Binary Classifier. Columns in the inference data that were not present in the training dataset are ignored.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed5a892-8de4-44ee-946d-2fefe2671015",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "create_classification_view"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_df.write.mode(\"overwrite\").save_as_table(\"training_fd_table\")\n",
    "\n",
    "session.sql(\"CREATE OR REPLACE VIEW fraud_classification_training_view AS SELECT IS_FRAUD,LATITUDE,LONGITUDE,LOCATION,TOTAL_TRANSACTIONS,STDDEV_TRANSACTION_AMOUNT,NUM_UNIQUE_MERCHANTS, MEAN_WEEKLY_SPENT,MEAN_MONTHLY_SPENT,MEAN_YEARLY_SPENT,TIME_ELAPSED,CLICKS,CUMULATIVE_CLICKS,CUMULATIVE_LOGINS_PER_HOUR FROM training_fd_table\").collect()\n",
    "\n",
    "val_df.drop(\"IS_FRAUD\").collect()\n",
    "val_df.write.mode(\"overwrite\").save_as_table(\"val_fd_table\")\n",
    "\n",
    "session.sql(\"CREATE OR REPLACE VIEW fraud_classification_val_view AS SELECT * EXCLUDE IS_FRAUD FROM val_fd_table\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b5ee2a-959d-475d-8333-936ccb48500d",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "view_validation"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM fraud_classification_val_view LIMIT 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27807db5-7aa4-408c-959c-76a0b19265db",
   "metadata": {
    "collapsed": false,
    "name": "Build_model"
   },
   "source": [
    "## Build the model\n",
    "We can create the classification model by running the following statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6298e68c-89f9-410b-b778-0a428a0095b5",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "create_fraud_classification_model"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE SNOWFLAKE.ML.CLASSIFICATION fraud_classification_model(\n",
    "    INPUT_DATA => SYSTEM$REFERENCE('view', 'fraud_classification_training_view'),\n",
    "    TARGET_COLNAME => 'IS_FRAUD'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22dc434-2200-4a42-b720-4d1c655c8edd",
   "metadata": {
    "collapsed": false,
    "name": "view_classification_model"
   },
   "source": [
    "View all classification models, use the SHOW command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b8fe61-4934-4846-beea-acf855dde9e8",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "show_classification"
   },
   "outputs": [],
   "source": [
    "SHOW SNOWFLAKE.ML.CLASSIFICATION;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e5e20e-9149-474f-ac48-81a74d3e6e21",
   "metadata": {
    "collapsed": false,
    "name": "streamlit_table"
   },
   "source": [
    "Add a table to use for the Streamlit App that will be used for ongoing Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e305f6da-cabb-444f-891a-2908bf36e7ec",
   "metadata": {
    "language": "sql",
    "name": "CC_APP_TBL_forstreamlit"
   },
   "outputs": [],
   "source": [
    "CREATE or replace table CC_APP_TBL AS SELECT * FROM CREDITCARD_TRANSACTIONS WHERE TRANSACTION_ID NOT IN (SELECT DISTINCT TRANSACTION_ID FROM training_fd_table);\n",
    "alter table CC_APP_TBL drop column IS_FRAUD;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c3b0a3-da88-47b8-9438-62a4423893cc",
   "metadata": {
    "collapsed": false,
    "name": "fraud_detection"
   },
   "source": [
    "Run inference (prediction) on a dataset, use the model’s PREDICT method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3a224d-6218-4aef-b8b0-abba597033fc",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "predict_fraud"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE fraud_predictions AS\n",
    "SELECT *,fraud_classification_model!PREDICT(INPUT_DATA => object_construct(*)) as predictions\n",
    "from fraud_classification_val_view;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca89568-8951-4b93-ad34-68b445f21f06",
   "metadata": {
    "collapsed": false,
    "name": "View_predictions"
   },
   "source": [
    "View the predictions.The model returns output in the following format. The prediction object includes predicted probabilities for each class and the predicted class based on the maximum predicted probability. The predictions are returned in the same order as the original features were provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1285fb-557b-4f94-b1c4-2e4add5c9394",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "view_predictions_table"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM fraud_predictions;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c087d-7e34-4264-b8d7-b8020787e067",
   "metadata": {
    "collapsed": false,
    "name": "class_probabilities"
   },
   "source": [
    "In the result set, we see that the model produces both a predicted class denoted by class as well giving us the probability of the respective class membership. Oftentimes, we may want to parse out the probabilities or the prediction directly, and have it in its own column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b4cf5d-9c8c-4ab7-a024-173408f25e84",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "view_prediction_class"
   },
   "outputs": [],
   "source": [
    "select * EXCLUDE PREDICTIONS,\n",
    "        predictions:class::STRING AS class,\n",
    "      round(predictions['probability'][class], 3) as probability\n",
    "from fraud_predictions;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6f3b97-fcdb-4bf8-952b-8b2afd754519",
   "metadata": {
    "collapsed": false,
    "name": "ConfusionMatrix"
   },
   "source": [
    "Now that we have built our classifier, we can begin to evaluate it to better understand both its performance as well as the primary factors within the dataset that were driving the predictions. Follow along below to see the various commands you may run to evalute your own classifier:\n",
    "\n",
    "# Confusion Matrix & Model Accuracy\n",
    "One of the most common ways of evaluating a classifier is by creating a Confusion Matrix, which allows us to visualize the types of errors that the model is making. Typically, they are used to calculate a classifier's Precision & Recall; which describe both the accuracy of a model when it predicts a certain class of interest (Precision), as well as how many of that specific class of interest were classified (recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd67e8f-30ae-401f-95b6-f416801e63d7",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "SHOW_CONFUSION_MATRIX"
   },
   "outputs": [],
   "source": [
    "CALL fraud_classification_model!SHOW_CONFUSION_MATRIX();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0018c7f-0c91-4d96-aa96-69d829206d72",
   "metadata": {
    "collapsed": false,
    "name": "show_evaluation_metrics"
   },
   "source": [
    "The show_evaluation_metrics calculates the following False Positive, False Negative, True Positive and True Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b3b85e-1222-410e-8665-2b5b49a56bae",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "evaluation_metrics"
   },
   "outputs": [],
   "source": [
    "CALL fraud_classification_model!SHOW_EVALUATION_METRICS();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409df329-1862-45e7-a016-6ce31268b5e6",
   "metadata": {
    "collapsed": false,
    "name": "threshold_metrics"
   },
   "source": [
    "The show_threshold_metrics provides raw counts and metrics for a specific threshold for each class. This can be used to plot ROC and PR curves or do threshold tuning if desired. The threshold varies from 0 to 1 for each specific class; "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fcb13a-7075-478c-b439-a0242ef07505",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "SHOW_THRESHOLD_METRICS"
   },
   "outputs": [],
   "source": [
    "CALL fraud_classification_model!SHOW_THRESHOLD_METRICS()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69f3ff5-fee9-40a0-bc49-034ac3fab3f2",
   "metadata": {
    "collapsed": false,
    "name": "Feature_Importance"
   },
   "source": [
    "# Feature Importances\n",
    "The last thing we want to understand when evaluating the classifier is to get a sense of the importance of each of the individual input columns or features we made use of. \n",
    "\n",
    "Better understand what's driving a model's prediction to give us more insight into the business process we are trying to model out\n",
    "Engineer new features or remove ones that are not too impactful to increase the model's performance.\n",
    "The ML Classification function provides a method to do just this, and provides us a ranked list of the relative importance of all the input features, such that their values are between 0 and 1, and the importances across all the features sum to be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3754281-6be9-4399-8771-34c77368fa57",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "show_featureimportance"
   },
   "outputs": [],
   "source": [
    "CALL fraud_classification_model!SHOW_FEATURE_IMPORTANCE();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7319e4d7-7516-4e5d-9270-fcac704774f1",
   "metadata": {
    "collapsed": false,
    "name": "Endofnotebook"
   },
   "source": [
    "This completes an end to end model building using Snowflake ML and detection of the fraud using a validation dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
