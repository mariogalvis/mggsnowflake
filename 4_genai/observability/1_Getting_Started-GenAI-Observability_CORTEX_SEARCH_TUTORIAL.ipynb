{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "vxrgs5zxozdfl2o4tbl6",
   "authorId": "184823401830",
   "authorName": "MGGSNOWFLAKE3",
   "authorEmail": "mggsnowflake3@gmail.com",
   "sessionId": "c17c1a02-7a49-4011-809d-aa77151d1a29",
   "lastEditTime": 1755485276015
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a4592fd-4b80-477a-a701-193c6c243b58",
   "metadata": {
    "collapsed": false,
    "name": "title",
    "resultHeight": 74
   },
   "source": "# Getting Started with AI Observability\n\nTo run, first install the following packages: `snowflake-ml-python`, `snowflake.core`, `trulens-core`, `trulens-providers-cortex`, `trulens-connectors-snowflake`\n\nhttps://github.com/Snowflake-Labs/sfguide-getting-started-with-ai-observability"
  },
  {
   "cell_type": "markdown",
   "id": "0a1550b9-345a-4b6d-9ee2-0cf064464a53",
   "metadata": {
    "collapsed": false,
    "name": "head_setup",
    "resultHeight": 60
   },
   "source": [
    "## Create the database, tables and warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3105267-f3f3-457e-ae9f-310469dd5c00",
   "metadata": {
    "collapsed": false,
    "language": "python",
    "name": "get_active_session",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "session = get_active_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "create_database_warehouse",
    "resultHeight": 0,
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE DATABASE IF NOT EXISTS cortex_search_tutorial_db;\n",
    "\n",
    "CREATE OR REPLACE WAREHOUSE cortex_search_tutorial_wh WITH\n",
    "     WAREHOUSE_SIZE='X-SMALL'\n",
    "     AUTO_SUSPEND = 120\n",
    "     AUTO_RESUME = TRUE\n",
    "     INITIALLY_SUSPENDED=TRUE;\n",
    "\n",
    " USE WAREHOUSE cortex_search_tutorial_wh;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e9ef02-2494-4b6b-b8ad-735ae46fbd05",
   "metadata": {
    "collapsed": false,
    "name": "create_info",
    "resultHeight": 150
   },
   "source": [
    "Note:\n",
    "\n",
    "The CREATE DATABASE statement creates a database. The database automatically includes a schema named PUBLIC.\n",
    "\n",
    "The CREATE WAREHOUSE statement creates an initially suspended warehouse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caaed33-9e4f-4d6f-bfee-594856707302",
   "metadata": {
    "collapsed": false,
    "name": "get_data",
    "resultHeight": 303
   },
   "source": [
    "## Get PDF data\n",
    "\n",
    "You will use a sample dataset of the Federal Open Market Committee (FOMC) meeting minutes for this example. This is a sample of twelve 10-page documents with meeting notes from FOMC meetings from 2023 and 2024. Download the files directly from your browser by following this link:\n",
    "\n",
    "[FOMC minutes sample](https://drive.google.com/file/d/1C6TdVjy6d-GnasGO6ZrIEVJQRcedDQxG/view)\n",
    "\n",
    "The complete set of FOMC minutes can be found at the [US Federal Reserve’s website](https://www.federalreserve.gov/monetarypolicy/fomccalendars.htm).\n",
    "\n",
    "Note: In a non-classroom setting, you would bring your own data, possibly already in a Snowflake stage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8014de4-0579-4afc-b9be-2dbd623d3d44",
   "metadata": {
    "collapsed": false,
    "name": "load_to_stage",
    "resultHeight": 60
   },
   "source": [
    "## Load data into Snowflake stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e8d596-146e-4a6f-8a7b-4187b05e39db",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "create_stage",
    "resultHeight": 0,
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE STAGE cortex_search_tutorial_db.public.fomc\n",
    "    DIRECTORY = (ENABLE = TRUE)\n",
    "    ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE');"
   ]
  },
  {
   "cell_type": "code",
   "id": "58cc3c22-eae4-4dd8-8d2a-37d13303a8bc",
   "metadata": {
    "language": "sql",
    "name": "cell2"
   },
   "outputs": [],
   "source": "--esto elimina la necesidad de hacer la carga manualmente\n\nCREATE OR REPLACE STAGE MGG_GENAI_OBSERVABILITY\n URL = 's3://mggsnowflake/genaiobservability';\n\nCOPY FILES INTO @FOMC\nFROM @MGG_GENAI_OBSERVABILITY;\n\nALTER STAGE FOMC REFRESH;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ebb1b9d5-d330-43df-ace2-7f9f8883a085",
   "metadata": {
    "collapsed": false,
    "name": "load_instructions",
    "resultHeight": 374
   },
   "source": [
    "Now upload the dataset. You can upload the dataset in Snowsight or using SQL. To upload in Snowsight:\n",
    "\n",
    "1. Sign in to Snowsight.\n",
    "\n",
    "2. Select Data in the left-side navigation menu.\n",
    "\n",
    "3. Select your database cortex_search_tutorial_db.\n",
    "\n",
    "4. Select your schema public.\n",
    "\n",
    "5. Select Stages and select fomc.\n",
    "\n",
    "6. On the top right, Select the + Files button.\n",
    "\n",
    "7. Drag and drop files into the UI or select Browse to choose a file from the dialog window.\n",
    "\n",
    "8. Select Upload to upload your file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1840b0d9-89a3-472f-aee5-92ae1717e231",
   "metadata": {
    "collapsed": false,
    "name": "head_verify_stage",
    "resultHeight": 60
   },
   "source": [
    "## Verify the PDF Files are uploaded to stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0aeb5-1683-47e0-a5a1-f253a0ee69e6",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "verify_stage",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "ls @cortex_search_tutorial_db.public.fomc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81011f41-48b1-4c38-8ed6-a5ee1f5d8289",
   "metadata": {
    "collapsed": false,
    "name": "head_parse_pdfs",
    "resultHeight": 60
   },
   "source": [
    "## Parse PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d08d4e-c732-48e9-b526-e3bc848f10d9",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "parse_pdfs",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE CORTEX_SEARCH_TUTORIAL_DB.PUBLIC.PARSED_FOMC_CONTENT AS SELECT \n",
    "      relative_path,\n",
    "      TO_VARCHAR(\n",
    "        SNOWFLAKE.CORTEX.PARSE_DOCUMENT(\n",
    "          @cortex_search_tutorial_db.public.fomc, \n",
    "          relative_path, \n",
    "          {'mode': 'LAYOUT'}\n",
    "        ) :content\n",
    "      ) AS parsed_text\n",
    "    FROM directory(@cortex_search_tutorial_db.public.fomc)\n",
    "    WHERE relative_path LIKE '%.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748401d-8846-408f-b35c-c9cdb58bcd1b",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "verify_parse",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM CORTEX_SEARCH_TUTORIAL_DB.PUBLIC.PARSED_FOMC_CONTENT LIMIT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277ada13-fbe9-4ee1-a57f-d540bbeb7dee",
   "metadata": {
    "name": "cell3",
    "collapsed": false
   },
   "source": "Valide el stage y haga refresh, para que el query anterior marque texto parseado"
  },
  {
   "cell_type": "markdown",
   "id": "2432741a-f082-4085-a15a-a67ebb6f0c05",
   "metadata": {
    "collapsed": false,
    "name": "head_chunk",
    "resultHeight": 102
   },
   "source": [
    "## Chunk text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fca862-936f-489c-be8b-3e71410914d2",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "chunk",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE CORTEX_SEARCH_TUTORIAL_DB.PUBLIC.CHUNKED_FOMC_CONTENT (\n",
    "    file_name VARCHAR,\n",
    "    CHUNK VARCHAR\n",
    ");\n",
    "\n",
    "INSERT INTO CORTEX_SEARCH_TUTORIAL_DB.PUBLIC.CHUNKED_FOMC_CONTENT (file_name, CHUNK)\n",
    "SELECT\n",
    "    relative_path,\n",
    "    c.value AS CHUNK\n",
    "FROM\n",
    "    CORTEX_SEARCH_TUTORIAL_DB.PUBLIC.PARSED_FOMC_CONTENT,\n",
    "    LATERAL FLATTEN( input => SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER (\n",
    "        parsed_text,\n",
    "        'markdown',\n",
    "        1800,\n",
    "        250\n",
    "    )) c;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175499b5-7c4a-4fa0-9182-ceeeb2ec5e2a",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "sql",
    "name": "verify_chunk",
    "resultHeight": 0,
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM CORTEX_SEARCH_TUTORIAL_DB.PUBLIC.CHUNKED_FOMC_CONTENT LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecbdbcd-6a4a-49ae-920f-f60524a2354f",
   "metadata": {
    "collapsed": false,
    "name": "head_create_search_service",
    "resultHeight": 60
   },
   "source": [
    "## Create Search Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b88ac-7fa2-408e-b7b4-44c2fe1539d1",
   "metadata": {
    "collapsed": false,
    "language": "sql",
    "name": "create_search_service",
    "resultHeight": 0,
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE CORTEX SEARCH SERVICE CORTEX_SEARCH_TUTORIAL_DB.PUBLIC.FOMC_SEARCH_SERVICE\n",
    "    ON chunk\n",
    "    WAREHOUSE = cortex_search_tutorial_wh\n",
    "    TARGET_LAG = '1 minute'\n",
    "    EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "    AS (\n",
    "    SELECT\n",
    "        file_name,\n",
    "        chunk\n",
    "    FROM CORTEX_SEARCH_TUTORIAL_DB.PUBLIC.CHUNKED_FOMC_CONTENT\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cc75d5-dd7f-4779-98a7-cc3013891ee8",
   "metadata": {
    "collapsed": false,
    "name": "head_use_search_service",
    "resultHeight": 60
   },
   "source": [
    "## Use the Search Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b999eb72-2f6c-4e56-908b-048bb2110540",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "use_search_service",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.core import Root\n",
    "from typing import List\n",
    "from snowflake.snowpark.session import Session\n",
    "\n",
    "class CortexSearchRetriever:\n",
    "\n",
    "    def __init__(self, snowpark_session: Session, limit_to_retrieve: int = 4):\n",
    "        self._snowpark_session = snowpark_session\n",
    "        self._limit_to_retrieve = limit_to_retrieve\n",
    "\n",
    "    def retrieve(self, query: str) -> List[str]:\n",
    "        root = Root(session)\n",
    "\n",
    "        search_service = (root\n",
    "          .databases[\"CORTEX_SEARCH_TUTORIAL_DB\"]\n",
    "          .schemas[\"PUBLIC\"]\n",
    "          .cortex_search_services[\"FOMC_SEARCH_SERVICE\"]\n",
    "        )\n",
    "        resp = search_service.search(\n",
    "          query=query,\n",
    "          columns=[\"chunk\"],\n",
    "          limit=self._limit_to_retrieve\n",
    "        )\n",
    "\n",
    "        if resp.results:\n",
    "            return [curr[\"chunk\"] for curr in resp.results]\n",
    "        else:\n",
    "            return []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46770ade-ff32-481d-b375-b25b41f1ab9f",
   "metadata": {
    "collapsed": false,
    "name": "head_tracing_setup"
   },
   "source": [
    "## Turn on OpenTelemetry Tracing\n",
    "\n",
    "Before we build the RAG, we want to enable TruLens-OpenTelemetry for tracing and observability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf3c55-cc8c-4ede-a16d-b21083ab44b7",
   "metadata": {
    "language": "python",
    "name": "turn_on_otel"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TRULENS_OTEL_TRACING\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9176c9cf-485a-4d7a-b41a-01bd2db4832c",
   "metadata": {
    "name": "cell1"
   },
   "source": [
    "Create a database and schema to store our traces and evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd4833c-836d-4072-bd45-4a844289a77b",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "create_observability_db_schema",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": "create database if not exists observability_db;\ncreate schema if not exists observability_db.observability_schema;"
  },
  {
   "cell_type": "code",
   "id": "83a26693-62d3-45b5-96a8-463259915cb8",
   "metadata": {
    "language": "python",
    "name": "set_current_schema"
   },
   "outputs": [],
   "source": "session.use_schema(\"observability_db.observability_schema\")\nsession.get_current_database() + '.' + session.get_current_schema()",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c1ddf32f-0af5-405f-b536-ff9c79cd94da",
   "metadata": {
    "collapsed": false,
    "name": "head_create_rag"
   },
   "source": [
    "## Create the RAG with instrumentation\n",
    "\n",
    "Develop the RAG system with integrated instrumentation. Including the span type and attributes in instrumentation will power evaluations of the spans captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e31278-11c1-49e2-88a6-04eb58da532d",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "create_rag",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "from snowflake.cortex import complete\n",
    "from trulens.core.otel.instrument import instrument\n",
    "from trulens.otel.semconv.trace import SpanAttributes\n",
    "\n",
    "class RAG:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.retriever = CortexSearchRetriever(snowpark_session=session, limit_to_retrieve=4)\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RETRIEVAL,\n",
    "        attributes={\n",
    "            SpanAttributes.RETRIEVAL.QUERY_TEXT: \"query\",\n",
    "            SpanAttributes.RETRIEVAL.RETRIEVED_CONTEXTS: \"return\",\n",
    "            }\n",
    "    )\n",
    "    def retrieve_context(self, query: str) -> list:\n",
    "        \"\"\"\n",
    "        Retrieve relevant text from vector store.\n",
    "        \"\"\"\n",
    "        return self.retriever.retrieve(query)\n",
    "\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.GENERATION)\n",
    "    def generate_completion(self, query: str, context_str: list) -> str:\n",
    "        \"\"\"\n",
    "        Generate answer from context.\n",
    "        \"\"\"\n",
    "        prompt = f\"\"\"\n",
    "          You are an expert assistant extracting information from context provided.\n",
    "          Answer the question in long-form, fully and completely, based on the context. Do not hallucinate.\n",
    "          If you don´t have the information just say so.\n",
    "          Context: {context_str}\n",
    "          Question:\n",
    "          {query}\n",
    "          Answer:\n",
    "        \"\"\"\n",
    "        response = \"\"\n",
    "        stream = complete(\"mistral-large2\", prompt, stream = True)\n",
    "        for update in stream:    \n",
    "          response += update\n",
    "          print(update, end = '')\n",
    "        return response\n",
    "\n",
    "    @instrument(\n",
    "        span_type=SpanAttributes.SpanType.RECORD_ROOT, \n",
    "        attributes={\n",
    "            SpanAttributes.RECORD_ROOT.INPUT: \"query\",\n",
    "            SpanAttributes.RECORD_ROOT.OUTPUT: \"return\",\n",
    "        })\n",
    "    def query(self, query: str) -> str:\n",
    "        context_str = self.retrieve_context(query)\n",
    "        return self.generate_completion(query, context_str)\n",
    "\n",
    "\n",
    "rag = RAG()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3307e02e-0a1f-4800-bb28-74e5910c6e31",
   "metadata": {
    "collapsed": false,
    "name": "head_register_rag"
   },
   "source": [
    "## Register the App\n",
    "\n",
    "Set metadata including application name and version, along with the snowpark session to store the experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5226476e-e829-4967-ad26-0cc303a59dcb",
   "metadata": {
    "codeCollapsed": false,
    "collapsed": false,
    "language": "python",
    "name": "register_rag",
    "resultHeight": 0
   },
   "outputs": [],
   "source": [
    "from trulens.apps.app import TruApp\n",
    "from trulens.connectors.snowflake import SnowflakeConnector\n",
    "\n",
    "tru_snowflake_connector = SnowflakeConnector(snowpark_session=session)\n",
    "\n",
    "app_name = \"fed_reserve_rag\"\n",
    "app_version = \"cortex_search\"\n",
    "\n",
    "tru_rag = TruApp(\n",
    "        rag,\n",
    "        app_name=app_name,\n",
    "        app_version=app_version,\n",
    "        connector=tru_snowflake_connector\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5413f89-2608-466c-b12f-7f422a4c1c97",
   "metadata": {
    "collapsed": false,
    "name": "head_add_run"
   },
   "source": [
    "## Configure and add experiment run\n",
    "\n",
    "Prepare a set of test queries to evaluate the RAG system.\n",
    "\n",
    "The test set can be either a dataframe in python or a table in Snowflake. In this example, we'll use a table in snowflake.\n",
    "\n",
    "First, download the [dataset provided](https://github.com/Snowflake-Labs/sfguide-getting-started-with-ai-observability/blob/main/fomc_dataset.csv).\n",
    "\n",
    "Then, upload `fomc_dataset.csv` to Snowflake:\n",
    "\n",
    "1. Select Data -> Add Data\n",
    "2. Choose the tile: Load data into a Table\n",
    "3. Upload `fomc_dataset.csv` from the [github repository]()\n",
    "4. Choose `OBSERVABILITY_DB.OBSERVABILITY_SCHEMA`, create a new table\n",
    "5. Name the new table `FOMC_DATA` , then click next.\n",
    "6. Update the column names to `QUERY`, and `GROUND_TRUTH_RESPONSE` and select Load.\n",
    "\n",
    "Set up the configuration for running experiments and add the run to TruLens."
   ]
  },
  {
   "cell_type": "code",
   "id": "0e3298b9-2003-4746-9785-a462699f98b8",
   "metadata": {
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": "-- ESTO ELIMINA LA NECESIDAD DE HACER EL ANTERIOR PASO MANUALMENTE\nCREATE OR REPLACE STAGE \"OBSERVABILITY_DB\".\"OBSERVABILITY_SCHEMA\".\"MGG_GENAI_OBSERVABILITY_DATA\"\n URL = 's3://mggsnowflake/genaiobservabilitydata';\n\nCREATE OR REPLACE TABLE \"OBSERVABILITY_DB\".\"OBSERVABILITY_SCHEMA\".\"FOMC_DATA\" ( QUERY VARCHAR , GROUND_TRUTH_RESPONSE VARCHAR ); \n\nCREATE TEMP FILE FORMAT \"OBSERVABILITY_DB\".\"OBSERVABILITY_SCHEMA\".\"CSV\"\n\tTYPE=CSV\n    SKIP_HEADER=0\n    FIELD_DELIMITER=','\n    TRIM_SPACE=TRUE\n    FIELD_OPTIONALLY_ENCLOSED_BY='\"'\n    REPLACE_INVALID_CHARACTERS=TRUE\n    DATE_FORMAT=AUTO\n    TIME_FORMAT=AUTO\n    TIMESTAMP_FORMAT=AUTO; \n\ncopy into \"OBSERVABILITY_DB\".\"OBSERVABILITY_SCHEMA\".\"FOMC_DATA\" \nfrom @MGG_GENAI_OBSERVABILITY_DATA\nfile_format=CSV;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb23d3-766d-42fb-b44a-d92f8c998be5",
   "metadata": {
    "language": "python",
    "name": "add_run",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from trulens.core.run import Run\nfrom trulens.core.run import RunConfig\n\nrun_name = \"experiment_1_run\"\n\nrun_config = RunConfig(\n    run_name=run_name,\n    dataset_name=\"FOMC_DATA\",\n    description=\"Questions about the Federal Open Market Committee meetings\",\n    label=\"fomc_rag_eval\",\n    source_type=\"TABLE\",\n    dataset_spec={\n        \"input\": \"QUERY\",\n        \"ground_truth_output\":\"GROUND_TRUTH_RESPONSE\",\n    },\n)\n\nrun: Run = tru_rag.add_run(run_config=run_config)"
  },
  {
   "cell_type": "markdown",
   "id": "57f4133b-ef2c-4966-b437-f2de5d19228a",
   "metadata": {
    "collapsed": false,
    "name": "head_start_run"
   },
   "source": [
    "## Start the run\n",
    "\n",
    "Start the experiment run with the prepared test set. Doing so will invoke the application in batch using the inputs in the dataset you provided in the run."
   ]
  },
  {
   "cell_type": "code",
   "id": "d134e51e-cca7-4fd6-a7eb-04d05faf53be",
   "metadata": {
    "language": "python",
    "name": "upsize_warehouse"
   },
   "outputs": [],
   "source": "import pandas as pd\n\nsession.sql(\n    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} \\\n    SET WAREHOUSE_SIZE='X-Large';\"\n).collect()\n\nwhs = pd.DataFrame(session.sql(\"show warehouses\").collect())[['name', 'size']]\ncurrent_wh = session.get_current_warehouse().strip('\"')\ncurrent_wh_size = whs.loc[whs['name'] == current_wh, 'size'].iloc[0]\n\nprint(f\"Current Warehouse: {current_wh} ({current_wh_size})\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ca2ee-c284-47fa-8fb4-193e8ba258bc",
   "metadata": {
    "language": "python",
    "name": "start_run"
   },
   "outputs": [],
   "source": [
    "run.start()"
   ]
  },
  {
   "cell_type": "code",
   "id": "18226450-210b-4677-8438-f24b60673b65",
   "metadata": {
    "language": "python",
    "name": "downsize_wh"
   },
   "outputs": [],
   "source": "import pandas as pd\n\nsession.sql(\n    f\"ALTER WAREHOUSE {session.get_current_warehouse()[1:-1]} \\\n    SET WAREHOUSE_SIZE='Small';\"\n).collect()\n\nwhs = pd.DataFrame(session.sql(\"show warehouses\").collect())[['name', 'size']]\ncurrent_wh = session.get_current_warehouse().strip('\"')\ncurrent_wh_size = whs.loc[whs['name'] == current_wh, 'size'].iloc[0]\n\nprint(f\"Warehouse Downsized: {current_wh} ({current_wh_size})\")",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "75aaf6d5-9447-4af1-b0ad-577343aa55d4",
   "metadata": {
    "collapsed": false,
    "name": "head_compute_metrics"
   },
   "source": [
    "## Compute metrics on the run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117230cb-4d72-49b7-87fa-4c16551bb700",
   "metadata": {
    "language": "python",
    "name": "compute_metrics"
   },
   "outputs": [],
   "source": [
    "run.compute_metrics([\n",
    "    \"answer_relevance\",\n",
    "    \"context_relevance\",\n",
    "    \"groundedness\",\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1db8b38-2e1d-4054-9fc5-833da59f7aac",
   "metadata": {
    "collapsed": false,
    "name": "head_navigate_ai_observability"
   },
   "source": [
    "## Evaluation Results\n",
    "\n",
    "To view evaluation results:\n",
    "* Login to [Snowsight](https://app.snowflake.com/).\n",
    "* Navigate to **AI & ML** -> **Evaluations** from the left navigation menu.\n",
    "* Select “FOMC RAG CHATBOT” to view the runs, see detailed traces and compare runs."
   ]
  }
 ]
}